1. Container and group FDs passed to secondary process, but not device FD
=========================================================================

For an initial test of multiprocess VFIO functionality had:
a. A primary process spawn a secondary process.
b. The secondary process was spawned after the primary had called open_vfio_devices_matching_filter()
c. The primary process attempted to call open_vfio_devices_matching_filter() in the same way as the primary.
   As expected based upon previous tests, the secondary process failed with EBUSY attempting to open the group FD
   since had already been opened by the primary process.
d. Added some debug to display the file descriptors in the primary and secondary processes.
e. Realised that open_vfio_device() is *not* using the O_CLOEXEC flag when opens the container and group FDs,
   so they remain open in the secondary.
f. The primary uses the VFIO_GROUP_GET_DEVICE_FD ioctl() to open the device FD, and that isn't open in the secondary.

[mr_halfword@skylake-alma release]$ nite_or_lite_fury_tests/test_general_primary 
Opening device 0000:2e:00.0 (10ee:7011) with IOMMU group 86
Enabling bus master for 0000:2e:00.0
container_fd=4
  0000:2e:00.0 : group_fd=5 device_fd=6
Contents of /proc/23771/fd in test_general_primary:
  fd 0 -> /dev/pts/0
  fd 1 -> /dev/pts/0
  fd 2 -> /dev/pts/0
  fd 3 -> /sys/devices/pci0000:2c/0000:2c:02.0/0000:2e:00.0/config
  fd 4 -> /dev/vfio/vfio
  fd 5 -> /dev/vfio/86
  fd 6 -> anon_inode:[vfio-device]
Contents of /proc/23772/fd in test_general_secondary:
  fd 0 -> /dev/pts/0
  fd 1 -> /dev/pts/0
  fd 2 -> /dev/pts/0
  fd 4 -> /dev/vfio/vfio
  fd 5 -> /dev/vfio/86
Opening device 0000:2e:00.0 (10ee:7011) with IOMMU group 86
open (/dev/vfio/86) failed : Device or resource busy


2. Secondary process uses container and group FDs from primary, and opens device FD
===================================================================================

open_vfio_device() was modified to automatically detect it was running in a secondary process, by container and group FDs
were already open, and just have to open the device FD. 

The test_general_primary process is able to spawn test_general_secondary which can successfully access the
device memmapped BARs via vfio:
[mr_halfword@skylake-alma release]$ nite_or_lite_fury_tests/test_general_primary 
Opening device 0000:2e:00.0 (10ee:7011) with IOMMU group 86
Enabling bus master for 0000:2e:00.0
container_fd=4
  0000:2e:00.0 : group_fd=5 device_fd=6
Contents of /proc/27997/fd in test_general_primary:
  fd 0 -> /dev/pts/0
  fd 1 -> /dev/pts/0
  fd 2 -> /dev/pts/0
  fd 3 -> /sys/devices/pci0000:2c/0000:2c:02.0/0000:2e:00.0/config
  fd 4 -> /dev/vfio/vfio
  fd 5 -> /dev/vfio/86
  fd 6 -> anon_inode:[vfio-device]
Contents of /proc/27998/fd in test_general_secondary:
  fd 0 -> /dev/pts/0
  fd 1 -> /dev/pts/0
  fd 2 -> /dev/pts/0
  fd 4 -> /dev/vfio/vfio
  fd 5 -> /dev/vfio/86
Opening device 0000:2e:00.0 (10ee:7011) with IOMMU group 86
Found NiteFury board version 0x2 for PCI device 0000:2e:00.0 IOMMU group 86
Temp C=34.7
VCCInt=1.03
vccaux=1.78
vbram=1.03


3. Secondary processes use container and group FDs from primary, and opens device FD
====================================================================================

The nite_or_lite_fury_tests were changed to:
a. Remove the test_general_secondary executable, as following open_vfio_device() automatically detecting when running in
   a secondary process a separate executable wasn't necessary.
b. test_primary takes arguments on how many secondary processes to launch

This allows both test_general and test_ddr (which test different BARs in the device) to both be launched together
and successfully open the device FD on one run when compiled for release:
[mr_halfword@skylake-alma release]$ nite_or_lite_fury_tests/test_primary test_general test_ddr 
Opening device 0000:2e:00.0 (10ee:7011) with IOMMU group 86
Enabling bus master for 0000:2e:00.0
container_fd=4
  0000:2e:00.0 : group_fd=5 device_fd=6
Contents of /proc/29949/fd in test_primary:
  fd 0 -> /dev/pts/0
  fd 1 -> /dev/pts/0
  fd 2 -> /dev/pts/0
  fd 3 -> /sys/devices/pci0000:2c/0000:2c:02.0/0000:2e:00.0/config
  fd 4 -> /dev/vfio/vfio
  fd 5 -> /dev/vfio/86
  fd 6 -> anon_inode:[vfio-device]
Opening device 0000:2e:00.0 (10ee:7011) with IOMMU group 86
Opening device 0000:2e:00.0 (10ee:7011) with IOMMU group 86
    control: I/O- Mem+ BusMaster+
Testing NiteFury board version 0x2 with DDR size 0x40000000 for PCI device 0000:2e:00.0 IOMMU group 86
Found NiteFury board version 0x2 for PCI device 0000:2e:00.0 IOMMU group 86
Temp C=34.9
VCCInt=1.03
vccaux=1.78
vbram=1.03
Size of DMA descriptors used for h2c: [0]=0xfffffff [1]=0xfffffff [2]=0xfffffff [3]=0xfffffff [4]=0x4
Print wrote 0x40000000 bytes to card using DMA in 809870397 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809870046 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809869358 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809869134 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809869634 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809868158 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809877269 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809869824 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809869998 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809869442 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809869591 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809869212 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809870093 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809870454 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809870359 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809871884 ns
Test pattern pass

On a second attempt to run with coverage then test_general failed with EBUSY in mmap():
[mr_halfword@skylake-alma coverage]$ nite_or_lite_fury_tests/test_primary test_general test_ddr 
Opening device 0000:2e:00.0 (10ee:7011) with IOMMU group 86
Enabling bus master for 0000:2e:00.0
container_fd=4
  0000:2e:00.0 : group_fd=5 device_fd=6
Contents of /proc/30254/fd in test_primary:
  fd 0 -> /dev/pts/0
  fd 1 -> /dev/pts/0
  fd 2 -> /dev/pts/0
  fd 3 -> /sys/devices/pci0000:2c/0000:2c:02.0/0000:2e:00.0/config
  fd 4 -> /dev/vfio/vfio
  fd 5 -> /dev/vfio/86
  fd 6 -> anon_inode:[vfio-device]
Opening device 0000:2e:00.0 (10ee:7011) with IOMMU group 86
Opening device 0000:2e:00.0 (10ee:7011) with IOMMU group 86
mmap() failed : Device or resource busy
    control: I/O- Mem+ BusMaster+
Testing NiteFury board version 0x2 with DDR size 0x40000000 for PCI device 0000:2e:00.0 IOMMU group 86
Size of DMA descriptors used for h2c: [0]=0xfffffff [1]=0xfffffff [2]=0xfffffff [3]=0xfffffff [4]=0x4
Print wrote 0x40000000 bytes to card using DMA in 809871189 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809869912 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809873824 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809868658 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809871791 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809868742 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809869260 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809875811 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809869425 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809871600 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809869763 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809868833 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809869190 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809876951 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809869043 ns
Test pattern pass
Print wrote 0x40000000 bytes to card using DMA in 809877042 ns
Test pattern pass
[mr_halfword@skylake-alma coverage]$ PATH=~/lcov/bin:/opt/GNAT/2021/bin/:$PATH ../../collect_coverage.sh 
geninfo: Warning: /home/mr_halfword/fpga_sio/software_tests/eclipse_project/source/vfio_access/vfio_access.c:1033: unexecuted block on non-branch line with non-zero hit count.  Use "geninfo --rc geninfo_unexecuted_blocks=1 to set count to zero.

This indicates a timing issue with the above approach where the secondary processes both open the device FD
rather than getting passed from the primary process.

Also, the fork() coverage is reporting an issue.

For the fork() coverage issue:
a. The compiler settings were already causing the coverage __gcov_fork() and __gcov_execv() wrapper functions to be used,
   as confirmed by using Eclipse to disassemble the test_primary executable built for coverage.
b. When the geninfo "unexecuted block on non-branch line with non-zero hit count" warning was displayed the issue is that the
   fprintf() error statement after the execv() call was shown as executed in the coverage, even though the error was reported
   when the test was run (since the execv call was successful):
    1026                 :           2 :         pid = fork ();
    1027         [ +  + ]:           4 :         if (pid == 0)
    1028                 :             :         {
    1029                 :             :             /* In child */
    1030                 :           2 :             (void) execv (process->executable, process->argv);
    1031                 :             : 
    1032                 :             :             /* An error has occurred if execvp returns */
    1033                 :           2 :             fprintf (stderr, "execvp (%s) failed : %s\n", process->executable, strerror (errno));
    1034                 :           0 :             exit (EXIT_FAILURE);
    1035                 :             :         }
c. Added "--rc geninfo_unexecuted_blocks=1" to the lcov command as suggested by the warning. That stopped the warning, and
   in the coverage the fprintf() error statement is no longer shown as executed:
    1026                 :           2 :         pid = fork ();
    1027         [ +  + ]:           4 :         if (pid == 0)
    1028                 :             :         {
    1029                 :             :             /* In child */
    1030                 :           2 :             (void) execv (process->executable, process->argv);
    1031                 :             : 
    1032                 :             :             /* An error has occurred if execv returns */
    1033                 :           0 :             fprintf (stderr, "execv (%s) failed : %s\n", process->executable, strerror (errno));
    1034                 :           0 :             exit (EXIT_FAILURE);
    1035                 :             :         }


4. VFIO_IOMMU_MAP_DMA failed with EPERM when two processes try and map the same IOVA
====================================================================================

Can now run test_ddr and time_dma_blkram as secondary processes, each targetting DMA in different FPGA designs.

What happens is one process is successful, and the other fails with EPERM from the ioctl(VFIO_IOMMU_MAP_DMA).
In this code both processes start from the same next_iova, and the EPERM is due to attempting to allocate an IOVA
which is already in use by the container. next_iova is only advanced if VFIO_IOMMU_MAP_DMA is successful, which explains
why the EPERM occurs on every VFIO_IOMMU_MAP_DMA attempt in the affected process.

Whereas if launch as two processes at the same time they are successful which is why think the IOVA conflict is per-container.

[mr_halfword@skylake-alma coverage]$ nite_or_lite_fury_tests/test_primary test_ddr time_dma_blkram 
Opening device 0000:15:00.0 (10ee:7024) with IOMMU group 41
Enabling bus master for 0000:15:00.0
Opening device 0000:2e:00.0 (10ee:7011) with IOMMU group 86
Enabling bus master for 0000:2e:00.0
container_fd=4
  0000:15:00.0 : group_fd=5 device_fd=6
  0000:2e:00.0 : group_fd=7 device_fd=8
Contents of /proc/8927/fd in test_primary:
  fd 0 -> /dev/pts/0
  fd 1 -> /dev/pts/0
  fd 2 -> /dev/pts/0
  fd 3 -> /sys/devices/pci0000:2c/0000:2c:02.0/0000:2e:00.0/config
  fd 4 -> /dev/vfio/vfio
  fd 5 -> /dev/vfio/41
  fd 6 -> anon_inode:[vfio-device]
  fd 7 -> /dev/vfio/86
  fd 8 -> anon_inode:[vfio-device]
Opening device 0000:15:00.0 (10ee:7024) with IOMMU group 41
Opening device 0000:2e:00.0 (10ee:7011) with IOMMU group 86
    control: I/O- Mem+ BusMaster+
Testing NiteFury board version 0x2 with DDR size 0x40000000 for PCI device 0000:2e:00.0 IOMMU group 86
    control: I/O- Mem+ BusMaster+
Testing dma_blkram device with memory size 0x128000 for PCI device 0000:15:00.0 IOMMU group 41
VFIO_IOMMU_MAP_DMA of size 4096 failed : Operation not permitted
VFIO_IOMMU_MAP_DMA of size 1212416 failed : Operation not permitted
VFIO_IOMMU_MAP_DMA of size 1212416 failed : Operation not permitted
Size of DMA descriptors used for h2c: [0]=0xfffffff [1]=0xfffffff [2]=0xfffffff [3]=0xfffffff [4]=0x4
Size of DMA descriptors used for c2h: [0]=0xfffffff [1]=0xfffffff [2]=0xfffffff [3]=0xfffffff [4]=0x4
Test pattern pass
Test pattern pass
Test pattern pass
Test pattern pass
Test pattern pass
Test pattern pass
Test pattern pass
Test pattern pass
Test pattern pass
Test pattern pass
Test pattern pass
Test pattern pass
Test pattern pass
Test pattern pass
Test pattern pass
Test pattern pass
host-to-card DMA timing for 16 transfers of 1073741824 bytes:
   Min = 1325.803270 (Mbytes/sec)
  Mean = 1325.819259 (Mbytes/sec)
   Max = 1325.822420 (Mbytes/sec)
card-to-host DMA timing for 16 transfers of 1073741824 bytes:
   Min = 1130.561636 (Mbytes/sec)
  Mean = 1130.575083 (Mbytes/sec)
   Max = 1130.592086 (Mbytes/sec)


[mr_halfword@skylake-alma coverage]$ nite_or_lite_fury_tests/test_primary test_ddr time_dma_blkram 
Opening device 0000:15:00.0 (10ee:7024) with IOMMU group 41
Enabling bus master for 0000:15:00.0
Opening device 0000:2e:00.0 (10ee:7011) with IOMMU group 86
Enabling bus master for 0000:2e:00.0
container_fd=4
  0000:15:00.0 : group_fd=5 device_fd=6
  0000:2e:00.0 : group_fd=7 device_fd=8
Contents of /proc/9835/fd in test_primary:
  fd 0 -> /dev/pts/0
  fd 1 -> /dev/pts/0
  fd 2 -> /dev/pts/0
  fd 3 -> /sys/devices/pci0000:2c/0000:2c:02.0/0000:2e:00.0/config
  fd 4 -> /dev/vfio/vfio
  fd 5 -> /dev/vfio/41
  fd 6 -> anon_inode:[vfio-device]
  fd 7 -> /dev/vfio/86
  fd 8 -> anon_inode:[vfio-device]
Opening device 0000:15:00.0 (10ee:7024) with IOMMU group 41
Opening device 0000:2e:00.0 (10ee:7011) with IOMMU group 86
    control: I/O- Mem+ BusMaster+
Testing dma_blkram device with memory size 0x128000 for PCI device 0000:15:00.0 IOMMU group 41
    control: I/O- Mem+ BusMaster+
Testing NiteFury board version 0x2 with DDR size 0x40000000 for PCI device 0000:2e:00.0 IOMMU group 86
VFIO_IOMMU_MAP_DMA of size 4096 failed : Operation not permitted
Size of DMA descriptors used for h2c: [0]=0x128000
Size of DMA descriptors used for c2h: [0]=0x128000
VFIO_IOMMU_MAP_DMA of size 1073741824 failed : Operation not permitted
VFIO_IOMMU_MAP_DMA of size 1073741824 failed : Operation not permitted
Test pattern pass
host-to-card DMA timing for 14170 transfers of 1212416 bytes:
   Min = 1692.973221 (Mbytes/sec)
  Mean = 1754.749368 (Mbytes/sec)
   Max = 1757.702896 (Mbytes/sec)
card-to-host DMA timing for 14170 transfers of 1212416 bytes:
   Min = 1386.413691 (Mbytes/sec)
  Mean = 1413.675297 (Mbytes/sec)
   Max = 1413.863234 (Mbytes/sec)
